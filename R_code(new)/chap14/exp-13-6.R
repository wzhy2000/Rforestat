library(foreach)
library(doParallel)
library(neuralnet)
library(forestat)
library(stringr)
data("picea")

# æ•°æ®å¤„ç†
# AGB = Stem + Branch + Foliage + Fruit
picea$AGB <- picea$STEM + picea$BRANCH + picea$FOLIAGE + picea$FRUIT


set.seed(123)
idx.train <- sample(nrow(picea), 0.7 * nrow(picea))
picea.train <- picea[idx.train, ]
picea.test <- picea[-idx.train, ]

x.train <- picea.train[, c("LH", "LHCB", "CPA", "D0", "H0", "HCB0", "CW")]
y.train <- picea.train$AGB
x.test <- picea.test[, c("LH", "LHCB", "CPA", "D0", "H0", "HCB0", "CW")]
y.test <- picea.test$AGB

picea.test$AGB <- (picea.test$AGB - min(picea.train$AGB)) / (max(picea.train$AGB) - min(picea.train$AGB))
picea.train$AGB <- (picea.train$AGB - min(picea.train$AGB)) / (max(picea.train$AGB) - min(picea.train$AGB))

picea.train <- picea.train[,c("LH", "LHCB", "CPA", "D0", "H0", "HCB0", "CW", "AGB")]
picea.test <- picea.test[,c("LH", "LHCB", "CPA", "D0", "H0", "HCB0", "CW", "AGB")]


# è®¡ç®—è®­ç»ƒé›†çš„æœ?å¤§å?¼å’Œæœ?å°å??
min.train <- apply(picea.train[, -ncol(picea.train)], 2, min)  # æœ?å°å??
max.train <- apply(picea.train[, -ncol(picea.train)], 2, max)  # æœ?å¤§å??

# å½’ä¸€åŒ–å‡½æ•?
normalize <- function(x, min_val, max_val) {
  return((x - min_val) / (max_val - min_val))
}

# å¯¹è®­ç»ƒé›†è¿›è¡Œå½’ä¸€åŒ–ï¼ˆå¯é?‰ï¼‰
for (col in names(min.train)) {
  picea.train[[col]] <- normalize(picea.train[[col]], min.train[col], max.train[col])
}

# å¯¹æµ‹è¯•é›†è¿›è¡Œå½’ä¸€åŒ?
picea.test <- picea.test
for (col in names(min.train)) {
  picea.test[[col]] <- normalize(picea.test[[col]], min.train[col], max.train[col])
}

# ç”±äºè¯¥æ¨¡å‹çš„ç½‘æ ¼æœç´¢æ—¶é—´å¯èƒ½è¾ƒé•¿ï¼Œå¯ä»¥é?šè¿‡åŠ è½½æ–‡ä»¶ 
# â€œLH+LHCB+CPA+D0+H0+HCB0+CW_2024-12-19_02-19-16.RDataâ€? 
# æ¥ç›´æ¥è·å–å·²ä¿å­˜çš„æ¨¡å‹ç»“æœï¼Œä»è?ŒèŠ‚çœè®¡ç®—æ—¶é—´ï¼Œç›´æ¥è·³è½¬åˆ°æŸ¥çœ‹ç»“æ? print(grid_search_results)
# å¹¶è¡Œè®¡ç®— 
# è®¾ç½®å¹¶è¡Œè®¡ç®—çš„æ ¸å¿ƒæ•°
num_cores <- 12  # detectCores()
cl <- makeCluster(num_cores)
registerDoParallel(cl)

# å®šä¹‰äº”æŠ˜äº¤å‰éªŒè¯å‡½æ•°
cross_validate_neuralnet <- function(data, tune_grid, folds = 5) {
  # åˆ›å»º K æŠ?
  cv_folds <- createFolds(data$AGB, k = folds, list = TRUE, returnTrain = TRUE)
  
  results <- foreach(params = iter(tune_grid, by = "row"), .combine = rbind, .packages = c("neuralnet", "caret")) %dopar% {
    fold_results <- lapply(cv_folds, function(train_index) {
      # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›?
      picea.train <- data[train_index, ]
      picea.test <- data[-train_index, ]
      
      # ä½¿ç”¨ tryCatch è®­ç»ƒæ¨¡å‹å’Œé¢„æµ?
      result <- tryCatch({
        # è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹
        nn_model <- neuralnet(
          AGB ~ LH + LHCB + CPA + D0 + H0 + HCB0 + CW,
          data = picea.train,
          hidden = unlist(params["hidden"]),
          linear.output = TRUE,
          err.fct = "sse",
          act.fct = "logistic",
          threshold = as.numeric(params["threshold"]),
          learningrate = as.numeric(params["learningrate"]),
          stepmax = as.numeric(params["stepmax"])
        )
        
        # é¢„æµ‹
        y.pred <- compute(nn_model, picea.test[, c("LH", "LHCB", "CPA", "D0", "H0", "HCB0", "CW")])$net.result
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        rmse <- sqrt(mean((y.pred - picea.test$AGB)^2, na.rm = TRUE))
        r_squared <- cor(y.pred, picea.test$AGB, use = "complete.obs")^2
        
        # è¿”å›æ­£å¸¸ç»“æœ
        return(data.frame(rmse = rmse, r_squared = r_squared))
        
      }, error = function(e) {
        # å¦‚æœå‘ç”Ÿé”™è¯¯ï¼Œè¿”å›? NA æ•°æ®æ¡?, è¿”å›çš„æ˜¯resultå˜é‡
        return(data.frame(rmse = NA, r_squared = NA))
      })
      
      # è¿™ä¸ªè¿”å›çš„æ˜¯fold_resultsçš„æŸä¸?ä¸ªå…ƒç´?
      return(result)
    })
    
    
    # æ±‡æ?»æ‰€æœ‰æŠ˜çš„æ?§èƒ½
    fold_results <- do.call(rbind, fold_results)
    if (all(is.na(fold_results$rmse))) {
      avg_rmse <- NA
      avg_r_squared <- NA
    } else {
      avg_rmse <- mean(fold_results$rmse, na.rm = TRUE)
      avg_r_squared <- mean(fold_results$r_squared, na.rm = TRUE)
    }
    
    
    # è¿”å›å½“å‰å‚æ•°ç»„åˆçš„å¹³å‡æ?§èƒ½
    data.frame(
      hidden = paste(unlist(params["hidden"]), collapse = ","),
      learningrate = as.numeric(params["learningrate"]),
      threshold = as.numeric(params["threshold"]),
      stepmax = as.numeric(params["stepmax"]),
      avg_rmse = avg_rmse,
      avg_r_squared = avg_r_squared
    )
  }
  
  return(results)
}


# è®¾ç½®è¶…å‚æ•°ç½‘æ ?
tune_grid <- expand.grid(
  hidden = list(c(10, 10)),  
  learningrate = seq(0.0001, 0.001, by = 0.0001), 
  threshold = c(0.1, 0.01, 0.001, 0.0001),
  stepmax = c(500000, 1200000))




# æ‰§è¡Œç½‘æ ¼æœç´¢
grid_search_results <- cross_validate_neuralnet(data = picea.train, 
                                                tune_grid = tune_grid, 
                                                folds = 10)

# åœæ­¢å¤šæ ¸å¹¶è¡Œ
stopCluster(cl)

# ä¿å­˜å·¥ä½œç©ºé—´
current_time <- format(Sys.time(), "%Y-%m-%d_%H-%M-%S")
file_name <- paste0("LH+LHCB+CPA+D0+H0+HCB0+CW_", current_time, ".RData")  # éœ?è¦ä¿®æ”?
save(grid_search_results, file = file_name)

# åŠ è½½grid_search_results
load("LH+LHCB+CPA+D0+H0+HCB0+CW_2025-02-09_14-39-42.RData")

# æŸ¥çœ‹ç»“æœ åŠ è½½å®?.RDataæ–‡ä»¶åä»è¿™é‡Œå¼?å§‹è¿è¡Œã??
print(grid_search_results)
grid_search_results[!is.na(grid_search_results$avg_rmse) & !is.na(grid_search_results$avg_r_squared), ]

# ç­›é?‰æœ€ä½³è¶…å‚æ•°ç»„åˆ
modela.nn.best <- grid_search_results[which.min(grid_search_results$avg_rmse), ]
print(modela.nn.best)

# æ¨¡å‹æ„å»ºä¸æ?§èƒ½è¯„ä¼°
con <- file("test.log")
sink(con, append=TRUE)
sink(con, append=TRUE, type="message")

tryCatch({
  set.seed(123)
  modela.nn <- neuralnet(AGB ~ LH + LHCB + CPA + D0 + H0 + HCB0 + CW, 
                         data = picea.train, 
                         hidden = as.numeric(unlist(strsplit(modela.nn.best$hidden, ","))), 
                         linear.output = TRUE, 
                         err.fct = "sse", 
                         act.fct = "logistic", 
                         threshold = as.numeric(modela.nn.best$threshold), 
                         learningrate = as.numeric(modela.nn.best$learningrate), 
                         stepmax = as.numeric(modela.nn.best$stepmax),
                         lifesign = "full",
                         lifesign.step = 1)
}, error = function(e) {
  message("Error occurred during neuralnet execution: ", e$message)
}, finally = {
  sink()
  sink(type="message")
})

# é¢„æµ‹å’Œè¯„ä¼?
y.pred <- predict(modela.nn, picea.test)
FittingEvaluationIndex(y.pred, picea.test$AGB)


# ç»˜åˆ¶æ®‹å·®å›?
data.nn <- data.frame(x = y.pred, y = y.pred - picea.test$AGB) 
p.nn <- ggplot(data.nn, aes(x = x, y = y)) +
  theme_light() +
  geom_point(color = "steelblue", size = 3, show.legend = F) +
  geom_hline(yintercept = c(0)) +
  geom_vline(xintercept = c(0)) +
  scale_x_continuous(limits = c(0, 0.6)) +
  scale_y_continuous(limits = c(-0.025, 0.025)) +
  labs(x = "åœ°ä¸Šç”Ÿç‰©é‡?(g/m2)", y = "æ®‹å·®(g/m2)") +
  theme(
    axis.title.x = element_text(size = 26, color = "black"),  # xè½´æ ‡é¢˜å­—ä½“å¤§å°?
    axis.title.y = element_text(size = 26, color = "black"),  # yè½´æ ‡é¢˜å­—ä½“å¤§å°?
    axis.text.x = element_text(size = 26, color = "black"),   # xè½´æ–‡æœ¬å­—ä½“å¤§å°?
    axis.text.y = element_text(size = 26, color = "black"),   # yè½´æ–‡æœ¬å­—ä½“å¤§å°?
    plot.title = element_text(size = 26, color = "black"),     # å›¾è¡¨æ ‡é¢˜å­—ä½“å¤§å°
    legend.title = element_text(size = 26, color = "black"),   # å›¾ä¾‹æ ‡é¢˜å­—ä½“å¤§å°
    legend.text = element_text(size = 26, color = "black"),      # å›¾ä¾‹æ–‡æœ¬å­—ä½“å¤§å°
    panel.grid.major = element_blank(),                         # å»æ‰ä¸»ç½‘æ ¼çº¿
    panel.grid.minor = element_blank()                          # å»æ‰æ¬¡ç½‘æ ¼çº¿
  )
pdf("å›?13.15a.pdf", width = 8, height = 6, family = "GB1")
p.nn
dev.off()

# ç»˜åˆ¶å˜åŒ–æ›²çº¿
training_log <- readLines(con)
thresh <- stringr::str_extract(training_log, "min thresh: [0-9\\.]+")
thresh <- as.numeric(stringr::str_replace(thresh, "min thresh: ", ""))
iteration <- seq_along(thresh)
df <- data.frame(Iteration = iteration, MinThresh = thresh)
pdf("å›?13.15b.pdf", width = 8, height = 6, family = "GB1")
ggplot(df, aes(x = Iteration, y = MinThresh)) +
  theme_light() + 
  geom_line(color = "black") +
  theme_minimal() +
  theme(
    axis.title.x = element_text(size = 26, color = "black"),  # xè½´æ ‡é¢˜å­—ä½“å¤§å°?
    axis.title.y = element_text(size = 26, color = "black"),  # yè½´æ ‡é¢˜å­—ä½“å¤§å°?
    axis.text.x = element_text(size = 26, color = "black"),   # xè½´æ–‡æœ¬å­—ä½“å¤§å°?
    axis.text.y = element_text(size = 26, color = "black"),   # yè½´æ–‡æœ¬å­—ä½“å¤§å°?
    plot.title = element_text(size = 26, color = "black"),     # å›¾è¡¨æ ‡é¢˜å­—ä½“å¤§å°
    legend.title = element_text(size = 26, color = "black"),   # å›¾ä¾‹æ ‡é¢˜å­—ä½“å¤§å°
    legend.text = element_text(size = 26, color = "black"),      # å›¾ä¾‹æ–‡æœ¬å­—ä½“å¤§å°
  )+
  xlim(0, 200) +        # è®¾ç½®xè½´æ˜¾ç¤ºèŒƒå›?
  ylim(-5, 45)           # è®¾ç½®yè½´æ˜¾ç¤ºèŒƒå›?

dev.off()

